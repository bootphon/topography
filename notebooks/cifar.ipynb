{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import uuid\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from topography.training import train, test\n",
    "from topography.models import resnet\n",
    "from topography.utils import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "weight_decay = 5e-4\n",
    "root = './cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandAugment(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root=f'{root}/data', train=True, download=True)\n",
    "train_length = int(0.9*len(dataset))\n",
    "train_set, val_set = random_split(\n",
    "    dataset, [train_length, len(dataset)-train_length],\n",
    "    [train_transform, test_transform])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root=f'{root}/data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = resnet(out_features=10, pretrained=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save directory: ./cifar10/runs/f3ca9016-4c6a-4566-825a-a074ececbd7b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb43a43ea3e4ad8bd5055b80b9ff2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train, epoch 1:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val, epoch 1: loss 0.211, acc 0.932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96237248e15d4281b81f2def9226ee12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train, epoch 2:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val, epoch 2: loss 0.166, acc 0.944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5731ea24d1764bd280a81fbc39ac83c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train, epoch 3:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val, epoch 3: loss 0.160, acc 0.947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36073f8767fa4e6fbcea3e1b9d6b962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train, epoch 4:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val, epoch 4: loss 0.154, acc 0.947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3750a1ff43ea4a978706f7036d49eb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train, epoch 5:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val, epoch 5: loss 0.142, acc 0.954\n",
      "test: loss 0.159, acc 0.948\n"
     ]
    }
   ],
   "source": [
    "save_dir = f'{root}/runs/{uuid.uuid4()}'\n",
    "print(f'Save directory: {save_dir}')\n",
    "results = {'train': {}, 'val': {}}\n",
    "for epoch in range(1, epochs+1):\n",
    "    results['train'][epoch] = train(model, train_loader, optimizer,\n",
    "                                    criterion, device, save_dir, epoch)\n",
    "    results['val'][epoch] = test(model, val_loader, criterion, device,\n",
    "                                 save_dir, 'val', epoch)\n",
    "results['test'] = test(model, test_loader, criterion, device, save_dir, 'test')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35e0b4034335b5c349218249c01092bcacbfaca87fce0d591779a5b0bb455cae"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-topo]",
   "language": "python",
   "name": "conda-env-.conda-topo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
